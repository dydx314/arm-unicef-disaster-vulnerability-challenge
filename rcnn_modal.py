import modal
from modal import Image, Volume, Mount
import detectron2
import yaml
import torch
import numpy as np
import pandas as pd 
from tqdm import tqdm

#This assumes we have called pre-processing to make everything 640x640 pixels

LOCAL_DIR = "."
REMOTE_DIR = "."
NUM_WORKERS = 8 
img_width = 640
img_height = 640

model_store_path = "/vol/models"
train_path = f"{model_store_path}/data/train"

# write a function that loads the dataset into detectron2's standard format
#here, for every file, need the following information to train detectron2:
#file_name, height, width, image_id, annotations
def get_data_dicts(dir):
    #dir is /data/train or /data/val
    img_dir = dir + "/images"
    label_dir = dir + "/labels"
    dataset_dicts = []

    #TO DO - make this faster
    with os.scandir(img_dir) as imgs:
        i = 0
        for img in imgs:
            #code to break after 20 images
            i += 1
            if i == 20:
                return dataset_dicts
            
            record = {}
            #height, width = cv2.imread(filename).shape[:2]
            record["file_name"] = img_dir + "/" + img.name
            record["image_id"] = img.name.split(".")[0]
            record["height"] = img_height
            record["width"] = img_width

            label_path = f"{label_dir}/{record['image_id']}.txt"
            if (os.path.isfile(label_path) == False):
                dataset_dicts.append(record)
                continue

            label_data = np.loadtxt(label_path)
            #now convert label_data to a 2d array if its 1D
            if len(label_data.shape) == 1:
                label_data = np.array([label_data])

            objs = []
            for i in range(len(label_data)):
                #2 0.044 0.406 0.042 0.056 is of the form x_center, y_center, width, height needs to be converted to x_min, y_min, x_max, y_max in ABS
                xmin = (label_data[i][1] - label_data[i][3]/2) * img_width
                ymin = (label_data[i][2] - label_data[i][4]/2) * img_height
                xmax = (label_data[i][1] + label_data[i][3]/2) * img_width
                ymax = (label_data[i][2] + label_data[i][4]/2) * img_height
                obj= {
                    'bbox': [xmin, ymin, xmax, ymax],
                    'bbox_mode': BoxMode.XYXY_ABS,
                    'category_id': label_data[i][0],
                    "iscrowd": 0
                }
                objs.append(obj)
            record["annotations"] = objs
            dataset_dicts.append(record)
    return dataset_dicts



def read_yaml_file(file_path):
    with open(file_path, 'r') as file:
        try:
            data = yaml.safe_load(file)
            return data
        except yaml.YAMLError as e:
            print("Error reading YAML:", e)
            return None
        
def print_files_in_path(path):
    try:
        # List all files and directories in the specified path
        with os.scandir(path) as entries:
            for entry in entries:
                # Check if the entry is a file
                if entry.is_file():
                    print(entry.name)
    except FileNotFoundError:
        print(f"The path {path} does not exist")
    except PermissionError:
        print(f"Permission denied for the path {path}")
    except Exception as e:
        print(f"An error occurred: {e}")


mount = Mount.from_local_dir(LOCAL_DIR, remote_path="/")

#to install detectron2 locally on a mac, i had to install gcc@11

#we build a container and copy our local training data to it
rcnn_image = (
    Image.debian_slim(python_version="3.9")
    .pip_install("numpy", "pandas", "torch", "torchvision", "tqdm", "opencv-python", "matplotlib")
    .apt_install("libgl1", "libglib2.0-0", "git")
    .run_commands("python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'", "python3 -m pip install pyyaml==5.1")
)

volume = modal.Volume.from_name("model-store")

with rcnn_image.imports():
    import yaml
    import torch
    import numpy as np
    import pandas as pd 
    from tqdm import tqdm
    import detectron2
    from detectron2.utils.logger import setup_logger
    from detectron2 import model_zoo
    from detectron2.data import DatasetCatalog, MetadataCatalog
    from detectron2.engine import DefaultPredictor
    from detectron2.config import get_cfg
    from detectron2.utils.visualizer import Visualizer
    from detectron2.engine import DefaultTrainer
    from detectron2.config import get_cfg
    from detectron2.utils.visualizer import ColorMode
    from detectron2.structures import BoxMode
    import matplotlib.pyplot as plt
    import random
    import os
    import cv2

app = modal.App(
    "rcnn-example"
)

#
@app.function(image=rcnn_image,volumes={model_store_path: volume},timeout=1200,gpu="any")
def train():
    setup_logger()

    #first, we need to register our dataset
    classes = ["Thatch", "Tin", "Other"]

    DatasetCatalog.register('zindi_houses', lambda: get_data_dicts(train_path))
    MetadataCatalog.get('zindi_houses').set(thing_classes=classes)
    house_detection_metadata = MetadataCatalog.get('zindi_houses')


    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
    cfg.DATASETS.TRAIN = ('zindi_houses',)
    cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
    cfg.DATALOADER.NUM_WORKERS = 2
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml")
    cfg.SOLVER.IMS_PER_BATCH = 2
    cfg.SOLVER.MAX_ITER = 1000
    cfg.SOLVER.STEPS = []        # do not decay learning rate
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4
    cfg.OUTPUT_DIR = model_store_path + "/detectron2"

    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
    trainer = DefaultTrainer(cfg) 
    trainer.resume_or_load(resume=False)
    trainer.train()

    #run inference
    predictor = DefaultPredictor(cfg)
    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model

    dataset_dicts = DatasetCatalog.get('zindi_houses')
    for d in random.sample(dataset_dicts, 5):    
        im = cv2.imread(d["file_name"])
        outputs = predictor(im)
        v = Visualizer(im[:, :, ::-1], metadata=house_detection_metadata, scale=0.8)
        v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        plt.figure(figsize = (14, 10))
        plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))
        plt.show()

    volume.commit()

#issue - model is not labeling anything for all of the classes
@app.function(image=rcnn_image,volumes={model_store_path: volume},gpu="any")
def run_test():
    
        
    #save submission file to volume
    submission_df.to_csv(f"{model_store_path}/submission.csv", index=False)
    volume.commit()



@app.local_entrypoint()
def main():
    #train.remote()
    train.remote()
