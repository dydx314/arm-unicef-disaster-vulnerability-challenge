import modal
from modal import Image, Volume, Mount
import detectron2
import yaml
import torch
import numpy as np
import pandas as pd 
from tqdm import tqdm

#This assumes we have called pre-processing to make everything 640x640 pixels

LOCAL_DIR = "."
REMOTE_DIR = "."
NUM_WORKERS = 8 
img_width = 640
img_height = 640

model_store_path = "/vol/models"
train_path = f"{model_store_path}/data/train"
val_path = f"{model_store_path}/data/val"

# write a function that loads the dataset into detectron2's standard format
#here, for every file, need the following information to train detectron2:
#file_name, height, width, image_id, annotations
def get_data_dicts(dir):
    #dir is /data/train or /data/val
    img_dir = dir + "/images"
    label_dir = dir + "/labels"
    dataset_dicts = []

    #TO DO - make this faster
    with os.scandir(img_dir) as imgs:
        for img in imgs:
            #code to break after 20 images
            
            record = {}
            #height, width = cv2.imread(filename).shape[:2]
            record["file_name"] = img_dir + "/" + img.name
            record["image_id"] = img.name.split(".")[0]
            record["height"] = img_height
            record["width"] = img_width

            #now process labels of instances in the image
            label_path = f"{label_dir}/{record['image_id']}.txt"
            if (os.path.isfile(label_path) == False):
                record["annotations"] = []
                dataset_dicts.append(record)
                continue

            label_data = np.loadtxt(label_path)
            #now convert label_data to a 2d array if its 1D
            if len(label_data.shape) == 1:
                label_data = np.array([label_data])

            objs = []
            for i in range(len(label_data)):
                #2 0.044 0.406 0.042 0.056 is of the form x_center, y_center, width, height needs to be converted to x_min, y_min, x_max, y_max in ABS
                xmin = (label_data[i][1] - label_data[i][3]/2) * img_width
                ymin = (label_data[i][2] - label_data[i][4]/2) * img_height
                xmax = (label_data[i][1] + label_data[i][3]/2) * img_width
                ymax = (label_data[i][2] + label_data[i][4]/2) * img_height
                obj= {
                    'bbox': [xmin, ymin, xmax, ymax],
                    'bbox_mode': BoxMode.XYXY_ABS,
                    'category_id': label_data[i][0],
                    "iscrowd": 0
                }
                objs.append(obj)
            record["annotations"] = objs
            dataset_dicts.append(record)
    return dataset_dicts

#for inference
def process_image(img_path, predictor):
    im = cv2.imread(img_path)
    outputs = predictor(im)
    return img_path, outputs

#this version draws bounding boxes on the image
def process_bb_image(img_path, predictor, cfg, output_dir):
    img = cv2.imread(img_path)
    outputs = predictor(img)
    
    # Visualize the predictions
    v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    # Save the image with bounding boxes
    result_img = out.get_image()[:, :, ::-1]
    result_path = os.path.join(output_dir, os.path.basename(img_path))
    print("saved image to", result_path)
    cv2.imwrite(result_path, result_img)

    return img_path, outputs

def read_yaml_file(file_path):
    with open(file_path, 'r') as file:
        try:
            data = yaml.safe_load(file)
            return data
        except yaml.YAMLError as e:
            print("Error reading YAML:", e)
            return None
        
def print_files_in_path(path):
    try:
        # List all files and directories in the specified path
        with os.scandir(path) as entries:
            for entry in entries:
                # Check if the entry is a file
                if entry.is_file():
                    print(entry.name)
    except FileNotFoundError:
        print(f"The path {path} does not exist")
    except PermissionError:
        print(f"Permission denied for the path {path}")
    except Exception as e:
        print(f"An error occurred: {e}")


mount = Mount.from_local_dir(LOCAL_DIR, remote_path="/")

#to install detectron2 locally on a mac, i had to install gcc@11

#we build a container and copy our local training data to it
rcnn_image = (
    Image.debian_slim(python_version="3.9")
    .pip_install("numpy", "pandas", "torch", "torchvision", "tqdm", "opencv-python", "matplotlib")
    .apt_install("libgl1", "libglib2.0-0", "git")
    .run_commands("python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'", "python3 -m pip install pyyaml==5.1")
)

volume = modal.Volume.from_name("model-store")

with rcnn_image.imports():
    import yaml
    import torch
    import numpy as np
    import pandas as pd 
    from tqdm import tqdm
    import detectron2
    from detectron2.utils.logger import setup_logger
    from detectron2 import model_zoo
    from detectron2.data import DatasetCatalog, MetadataCatalog
    from detectron2.engine import DefaultPredictor
    from detectron2.config import get_cfg
    from detectron2.utils.visualizer import Visualizer
    from detectron2.engine import DefaultTrainer
    from detectron2.config import get_cfg
    from detectron2.utils.visualizer import ColorMode
    from detectron2.structures import BoxMode
    from detectron2.checkpoint import DetectionCheckpointer
    from detectron2.modeling import build_model
    import matplotlib.pyplot as plt
    import random
    from concurrent.futures import ThreadPoolExecutor, as_completed
    import os
    import cv2

app = modal.App(
    "rcnn-example"
)

#train, use fast gpu cause why not
@app.function(image=rcnn_image,volumes={model_store_path: volume},timeout=12000,gpu="H100")
def train():
    setup_logger()

    #first, we need to register our dataset
    classes = ["Thatch", "Tin", "Other"]
    print("data dict", get_data_dicts(train_path))
    DatasetCatalog.register('zindi_houses', lambda: get_data_dicts(train_path))
    MetadataCatalog.get('zindi_houses').set(thing_classes=classes)
    house_detection_metadata = MetadataCatalog.get('zindi_houses')


    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
    cfg.DATASETS.TRAIN = ('zindi_houses',)
    cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
    cfg.DATALOADER.NUM_WORKERS = 8
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml")
    cfg.SOLVER.IMS_PER_BATCH = 8 #was 8
    cfg.SOLVER.MAX_ITER = 10000
    cfg.SOLVER.STEPS = [3000, 6000, 8000]        # decay learning rate
    cfg.SOLVER.GAMMA = 0.1
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.OUTPUT_DIR = model_store_path + "/detectron2/long_training"
    cfg.MODEL.DEVICE = "cuda"
    cfg.TEST.EVAL_PERIOD = 500     # Evaluate every 500 iterations
    cfg.freeze()

    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
    trainer = DefaultTrainer(cfg) 
    trainer.resume_or_load(resume=False)
    trainer.train()

    volume.commit()


#issue - model is not labeling anything for all of the classes
@app.function(image=rcnn_image,volumes={model_store_path: volume},timeout=12000,gpu="any")
def run_test():
    #run inference
    classes = ["Thatch", "Tin", "Other"]
    DatasetCatalog.register('zindi_houses', lambda: get_data_dicts(train_path))
    MetadataCatalog.get('zindi_houses').set(thing_classes=classes)

    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
    cfg.DATASETS.TRAIN = ('zindi_houses',)

    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.OUTPUT_DIR = model_store_path + "/detectron2/long_training"
    cfg.MODEL.DEVICE = "cuda"

    cfg.MODEL.WEIGHTS = f"{model_store_path}/detectron2/long_training/model_final.pth" 
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
    cfg.freeze()
    predictor = DefaultPredictor(cfg)

    inference = np.array([0,0])

    #run inference on same images it was trained on -> should work
    test_dir = f"{model_store_path}/data/test/images"
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        with os.scandir(test_dir) as imgs:
            for img in imgs:
                if img.is_file():  # Ensure it is a file and not a directory
                    futures.append(executor.submit(process_image, img.path, predictor))
        
        for future in as_completed(futures):
            img_path, outputs = future.result()

            pred_classes_np = outputs["instances"].pred_classes.cpu().numpy()
            counts = np.bincount(pred_classes_np, minlength=3)
            
            count_0, count_1, count_2 = counts[:3]
            filename = os.path.basename(img_path)

            inference = np.vstack((inference, [[filename +"_0", count_0], [filename +"_1", count_1], [filename +"_2", count_2]]))
    
    df = pd.DataFrame(inference)
    df.to_csv(f"{model_store_path}/output_final.csv", index=False, header=False)

    print(inference)

    volume.commit()

#issue - model is not labeling anything for all of the classes
@app.function(image=rcnn_image,volumes={model_store_path: volume},timeout=12000,gpu="any")
def draw_bb():
    #run inference
    classes = ["Thatch", "Tin", "Other"]
    DatasetCatalog.register('zindi_houses', lambda: get_data_dicts(train_path))
    MetadataCatalog.get('zindi_houses').set(thing_classes=classes)

    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
    cfg.DATASETS.TRAIN = ('zindi_houses',)

    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.OUTPUT_DIR = model_store_path + "/detectron2/long_training"
    cfg.MODEL.DEVICE = "cuda"

    cfg.MODEL.WEIGHTS = f"{model_store_path}/detectron2/long_training/model_final.pth" 
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
    cfg.freeze()
    predictor = DefaultPredictor(cfg)

    #run inference on same images it was trained on -> should work
    test_dir = f"{model_store_path}/data/val/images"
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        with os.scandir(test_dir) as imgs:
            i = 0
            for img in imgs:
                i += 1
                if i > 50:
                    break
                if img.is_file():  
                    futures.append(executor.submit(process_bb_image, img.path, predictor, cfg, f"{model_store_path}/"))
        
        for future in as_completed(futures):
            img_path, outputs = future.result()

    volume.commit()


@app.function(image=rcnn_image,volumes={model_store_path: volume},timeout=86400,gpu="any")
def run_val():
    #run inference on validation test
    classes = ["Thatch", "Tin", "Other"]
    DatasetCatalog.register('zindi_houses', lambda: get_data_dicts(val_path))
    MetadataCatalog.get('zindi_houses').set(thing_classes=classes)

    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
    cfg.DATASETS.TRAIN = ('zindi_houses',)

    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.OUTPUT_DIR = model_store_path + "/detectron2"
    cfg.MODEL.DEVICE = "cuda"

    cfg.MODEL.WEIGHTS = f"{model_store_path}/detectron2/long_training/model_final.pth" 
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
    cfg.freeze()
    predictor = DefaultPredictor(cfg)

    inference = np.array([0,0])

    #run inference on same images it was trained on -> should work
    val_dir = f"{model_store_path}/data/val/images"
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        with os.scandir(val_dir) as imgs:
            for img in imgs:
                if img.is_file():  # Ensure it is a file and not a directory
                    futures.append(executor.submit(process_image, img.path, predictor))
        
        for future in as_completed(futures):
            img_path, outputs = future.result()

            pred_classes_np = outputs["instances"].pred_classes.cpu().numpy()
            counts = np.bincount(pred_classes_np, minlength=3)
            
            count_0, count_1, count_2 = counts[:3]
            filename = os.path.basename(img_path)

            inference = np.vstack((inference, [[filename +"_0", count_0], [filename +"_1", count_1], [filename +"_2", count_2]]))
    
    df = pd.DataFrame(inference)
    df.to_csv(f"{model_store_path}/val_final.csv", index=False, header=False)

    print(inference)

    volume.commit()



@app.local_entrypoint()
def main():
    run_val.remote()
    #run_val.remote()
