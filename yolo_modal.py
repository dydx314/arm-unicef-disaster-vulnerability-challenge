import modal
from modal import Image, Volume, Mount
import yaml
import json
from tqdm import tqdm
from collections import defaultdict

EPOCHS = 1
BATCH_SIZE = 32
OPTIMIZER = "AdamW"
SEED = 42
NAME = f"Arm_Yolo_{EPOCHS}.pt"
DEVICE = 0#train on 4 gpus
VERBOSE = False
RESUME = False
PATIENCE = 20
img_width = 640 #https://docs.ultralytics.com/tasks/detect/ - size used here
img_height = 640
LOCAL_DIR = "."
REMOTE_DIR = "."
NUM_WORKERS = 8 

def read_yaml_file(file_path):
    with open(file_path, 'r') as file:
        try:
            data = yaml.safe_load(file)
            return data
        except yaml.YAMLError as e:
            print("Error reading YAML:", e)
            return None

def get_classes_count(pred_list):
    print(pred_list)
    classes_count = defaultdict(int)  # Initialize with default value of 0
    for j in pred_list:
        classes_count[j['class']] += 1
    return dict(classes_count)  # Convert back to a regular dictionary if needed
        
def print_files_in_path(path):
    try:
        # List all files and directories in the specified path
        with os.scandir(path) as entries:
            for entry in entries:
                # Check if the entry is a file
                if entry.is_file():
                    print(entry.name)
    except FileNotFoundError:
        print(f"The path {path} does not exist")
    except PermissionError:
        print(f"Permission denied for the path {path}")
    except Exception as e:
        print(f"An error occurred: {e}")


mount = Mount.from_local_dir(LOCAL_DIR, remote_path="/")

#we build a container and copy our local training data to it
yolo_image = (
    Image.debian_slim(python_version="3.9")
    .pip_install("matplotlib", "numpy", "pandas", "ultralytics", "Pillow", "tqdm")
    .apt_install("libgl1", "libglib2.0-0")
)

volume = modal.Volume.from_name("model-store")
model_store_path = "/vol/models"

with yolo_image.imports():
    import numpy as np
    import pandas as pd 
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    from ultralytics import YOLO
    import os
    import json
    from tqdm import tqdm
    from collections import defaultdict


app = modal.App(
    "yolo-example"
)

#the following two functions assume that you have used the modal CLI to copy data to ./data in the volume and have run clean_data locally
@app.function(image=yolo_image,volumes={model_store_path: volume},timeout=1200,gpu="any")
def train():
    #In future - use yolov8x which has x31 the parameters
    model = YOLO('yolov8n.pt')

    class_names = model.names
    print("The model can classify the following classes:")
    for idx, class_name in enumerate(class_names):
        print(f"{idx}: {class_name}")

    ### train
    model.train(
        data = f"{model_store_path}/data/data.yaml",
        task = 'detect',
        imgsz = (img_height, img_width),
        epochs = EPOCHS,
        batch = BATCH_SIZE,
        optimizer = OPTIMIZER,
        patience = PATIENCE,
        name = NAME,
        seed = SEED,
        val = True,
        resume = RESUME,
        device = DEVICE,
        verbose = VERBOSE,
        workers=NUM_WORKERS
    )

    model.save(f"{model_store_path}/{NAME}")

    class_names = model.names
    print("The model can classify the following classes:")
    print(class_names)

    #images have been resized. outputted bounding boxes do not need to be resized

    ### save model to volume
    submission_df = pd.DataFrame(columns=["image_id", "Target"])
    test = pd.read_csv(f"{model_store_path}/data/Test.csv")

    for index, row in tqdm(test.iterrows(), total=len(test)):
        path = f"{model_store_path}/data/test/images/{row['image_id']}.tif"
        if not os.path.isfile(path):
            continue
    
        # Perform inference
        results = model.predict(path)
        
        if not results or len(results) == 0 or results[0] is None:
            continue
        
        # Convert predictions to JSON and process class counts
        print(results[0])
        pred_json_str = results[0].tojson()
        pred_json = json.loads(pred_json_str)
        class_counts = get_classes_count(pred_json)
        
        # Create a DataFrame for the current image's predictions
        df = pd.DataFrame({
            "image_id": [f"{row['image_id']}_1", f"{row['image_id']}_2", f"{row['image_id']}_3"],
            "Target": [class_counts.get(0, 0), class_counts.get(1, 0), class_counts.get(2, 0)]
        }, columns=["image_id", "Target"])
        
        # Concatenate the current predictions to the submission DataFrame
        submission_df = pd.concat([submission_df, df], axis=0)
    
    #save submission file to volume
    submission_df.to_csv(f"{model_store_path}/submission.csv", index=False)
    volume.commit()


#FLAG - couldnt get this to load in model correctly - need to fix later
@app.function(image=yolo_image,volumes={model_store_path: volume},gpu="any")
def run_test():
    model = model(f"{model_store_path}/{NAME}")


    submission_df = pd.DataFrame(columns=["image_id", "Target"])
    test = pd.read_csv(f"{model_store_path}/data/Test.csv")

    for index, row in tqdm(test.iterrows(), total=len(test)):
        path = f"{model_store_path}/data/Images/{row['image_id']}.tif"
        if (os.path.isfile(path) == False):
            continue
        
        #here can set additional restrictions - https://docs.ultralytics.com/modes/predict/#inference-arguments
        pred = model.predict(path) #need to restrict classes
        print(pred)
        print(pred[0].tojson())
        pred_json = get_classes_count(pred[0].tojson())
    
        df = pd.DataFrame({"image_id" : [f"{row['image_id']}_1",
                                        f"{row['image_id']}_2",
                                        f"{row['image_id']}_3"],
                        "Target" : [pred_json[0], pred_json[1], pred_json[2]]},columns=["image_id", "Target"])
        submission_df = pd.concat([submission_df, df], axis = 0)
    
    #save submission file to volume
    submission_df.to_csv(f"{model_store_path}/submission.csv", index=False)
    volume.commit()


@app.local_entrypoint()
def main():
    train.remote()
