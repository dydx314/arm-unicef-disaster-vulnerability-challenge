
from modal_store import zindi_image, zindi_volumes, REMOTE_DIR
from modal import App

import utils

app = App()

with zindi_image.imports():
    import cv2
    import matplotlib.pyplot as plt
    import requests
    import torch
    from PIL import Image
    from transformers import AutoModelForZeroShotObjectDetection, AutoProcessor



@app.function(image=zindi_image, volumes=zindi_volumes, gpu="any")
def test_run(img_path, text):
    device="cuda"

    image = Image.open(img_path)
    model_id = "IDEA-Research/grounding-dino-tiny"

    processor = AutoProcessor.from_pretrained(model_id)
    model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)

    # results = []
    # images = [image]
    # for image in images:
    inputs = processor(images=image, text=text, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)

    result = processor.post_process_grounded_object_detection(
        outputs,
        inputs.input_ids,
        box_threshold=0.4,
        text_threshold=0.3,
        target_sizes=[image.size[::-1]],
    )[0]
    # results.append({
    #     "scores": list(result["scores"]),
    #     # "labels": result["labels"].tolist(),
    #     # "boxes": result["boxes"].tolist()
    # })
        # results.append(list(result["scores"]))
    print(result)
    result_dict = {
        "scores": result["scores"].tolist(),
        "labels": result["labels"],
        "boxes": result["boxes"].tolist(),
    }
    return result_dict

@app.local_entrypoint()
def main():
    img_file = "id_hfnc1vg4hi3y.tif"
    text = "light colored rectangles."

    image = Image.open(f"../../Downloads/Images/{img_file}")
    result_dict = test_run.remote(f"{REMOTE_DIR}/data/Images/{img_file}", text)
    print(result_dict)
    utils.plot_results(image, text, result_dict["scores"], result_dict["labels"], result_dict["boxes"], save_name=f"data/results/grounding_dino/{img_file}")
