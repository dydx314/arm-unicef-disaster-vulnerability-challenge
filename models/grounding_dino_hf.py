import cv2
import matplotlib.pyplot as plt
import requests
import torch
from PIL import Image
from transformers import AutoModelForZeroShotObjectDetection, AutoProcessor

import utils

IMG_DIR = "/home/data/Images"


def test_inference(device="cuda"):
    image_url = "http://images.cocodataset.org/val2017/000000039769.jpg"
    image = Image.open(requests.get(image_url, stream=True).raw)
    # Check for cats and remote controls
    text = "a cat. a remote control."

    results = run_detection([image], text, device)
    utils.plot_results(image, text, results)


def run_detection(images, text, box_threshold=0.4, text_threshold=0.3, device="cuda"):
    model_id = "IDEA-Research/grounding-dino-tiny"

    processor = AutoProcessor.from_pretrained(model_id)
    model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)

    results = []
    for image in images:
        inputs = processor(images=image, text=text, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = model(**inputs)

        result = processor.post_process_grounded_object_detection(
            outputs,
            inputs.input_ids,
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            target_sizes=[image.size[::-1]],
        )
        results.append(result[0])
    return results



def load_images():
    # TODO
    #Image.open(
    pass


def run():
    # load images
    images = load_images()
    text = ""  # TODO

    results = run_detection(images, text)
    utils.plot_results(images[0], text, results[0])
