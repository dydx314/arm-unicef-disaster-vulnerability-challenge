import torch
from groundingdino.models import build_model
from groundingdino.util.inference import annotate, load_image, predict
from groundingdino.util.slconfig import SLConfig
from groundingdino.util.utils import clean_state_dict
from huggingface_hub import hf_hub_download

CKPT_REPO_ID = "ShilongLiu/GroundingDINO"
CKPT_FILENAME = "groundingdino_swint_ogc.pth"
CKPT_CONFIG = "GroundingDINO_SwinT_OGC.cfg.py"

BOX_THRESHOLD = 0.35
TEXT_THRESHOLD = 0.25


def load_model_hf(device="cpu"):
    cache_config_file = hf_hub_download(repo_id=CKPT_REPO_ID, filename=CKPT_CONFIG)

    args = SLConfig.fromfile(cache_config_file)
    model = build_model(args)
    args.device = device

    cache_file = hf_hub_download(repo_id=CKPT_REPO_ID, filename=CKPT_FILENAME)
    checkpoint = torch.load(cache_file, map_location="cpu")
    log = model.load_state_dict(clean_state_dict(checkpoint["model"]), strict=False)
    print("Model loaded from {} \n => {}".format(cache_file, log))
    _ = model.eval()
    return model


def annotate_image(
    model,
    img_path,
    text_prompt,
    box_threshold=BOX_THRESHOLD,
    text_threshold=TEXT_THRESHOLD,
):
    image_source, image = load_image(img_path)

    boxes, logits, phrases = predict(
        model=model,
        image=image,
        caption=text_prompt,
        box_threshold=box_threshold,
        text_threshold=text_threshold,
    )
    annotated_frame = annotate(
        image_source=image_source, boxes=boxes, logits=logits, phrases=phrases
    )
    annotated_frame = annotated_frame[..., ::-1]  # BGR to RGB
    return annotated_frame
